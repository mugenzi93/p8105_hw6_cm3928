---
title: "p8105_hw6_cm3928"
author: "Clement Mugenzi"
date: "11/20/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(p8105.datasets)
library(modelr)
library(mgcv)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1

```{r}
weight_df = 
  read_csv("Data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  rename(gender = babysex, momwt = delwt, momrace = mrace, dadrace = frace,
         avg_smokes = smoken) %>% 
  mutate(
    gender = recode(gender, "1" = "Male", "2" = "Female"),
    dadrace = recode(dadrace, "1" = "White", "2" = "Black", "3" = "Asian",
                     "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
    momrace = recode(momrace, "1" = "White", "2" = "Black", "3" = "Asian",
                     "4" = "Puerto Rican", "8" = "Other"),
    malform = recode(malform, "0" = "Absent", "1" = "Present"),
    gender = factor(gender, levels = c("Male", "Female")),
    dadrace = factor(dadrace, levels = c("White", "Black", "Asian",
                                         "Puerto Rican", "Other",
                                         "unknown")),
    momrace = factor(momrace, levels = c("White", "Black", "Asian",
                                         "Puerto Rican", "Other")),
    malform = factor(malform, levels = c("Absent", "Present"))) %>% 
  arrange(gender) %>% view()
```

**Model-building Process:** 

Before deciding what predictors to include in my model, I first fitted the model with all independent variables to determine which ones had a significant p-value, meaning independnt variables directly affecting the baby's birthweight. Then I fitted the model using the selected predictors.


```{r}
bwt_lm = lm(bwt ~ gaweeks + avg_smokes + bhead + blength +
              gender + momrace, data = weight_df)
summary(bwt_lm)
```


## Plot of Residuals against Fitted values

**Adding Residuals and Fitted values to the dataframe using modelr:**


```{r}
weight_df1 = add_predictions(weight_df, bwt_lm)
weight_df2 = add_residuals(weight_df, bwt_lm)
weight_df = left_join(weight_df1, weight_df2)
```

```{r}
weight_df %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(color = "red", se = FALSE) +
  geom_hline(yintercept = 0) +
  labs(
    title = "Residuals against Fitted Values",
    x = "Fitted Values",
    y = "Residuals")
```

**Building two other models:**

1. First Model:

One using length at birth and gestational age as predictors (main effects only)

```{r}
bwt_lm1 = lm(bwt ~ gaweeks + blength, data = weight_df)
summary(bwt_lm1)
```

2. Second Model:

a model that uses head circumference, length, sex, and all interactions (including the three-way interaction) to test for any interaction that might be present.

```{r}
bwt_lm2 = lm(bwt ~ bhead * blength + blength * gender + gender * bhead +
                bhead * blength * gender, data = weight_df)
summary(bwt_lm2)
```


**Comparison:**

I will use the `crossv_mc` function from `modelr` to split `weight_df` into a train (80%) and test (20%) dataframes.

```{r}
cv_df =
  crossv_mc(weight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

I will then `map` the three built models above on the train dataframe, then also use `map2_dbl` to map the models to the `test` dataframe in an effort to generate the 
`Root mean squared errors` to help me make the decision of which of the three models is superior, meaning which model produces minimum `RMSE`.

```{r}
cv_df = 
  cv_df %>% 
  mutate(bwt_lm = map(train, ~bwt_lm),
         bwt_lm1 = map(train, ~bwt_lm1),
         bwt_lm2 = map(train, ~bwt_lm2)) %>% 
  mutate(rmse_Model_1 = map2_dbl(bwt_lm, test, ~rmse(model = .x, data = .y)),
         rmse_Model_2 = map2_dbl(bwt_lm1, test, ~rmse(model = .x, data = .y)),
         rmse_Model_3 = map2_dbl(bwt_lm2, test, ~rmse(model = .x, data = .y)))
```

Using a visualization method, I can now choose which model is superior.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "RMSE for each Model",
    x = "Models",
    y = "RMSE")
```

Therefore, I will choose `Model_1` that predicts the baby's birth weight using gestational age in weeks, the average number of cigarettes smoked per day during pregnancy, baby’s head circumference at birth, baby’s length at birth, baby's sex, and finally the mother's race as its predictor variables.

# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


Let's a write a function that will help us generate the bootstrap samples. This function will have the weather dataframe as its argument and should be able to draw a sample from the dataframe with replacement.

```{r}
boot_samples = function(df) {
  sample_frac(weather_df, replace = TRUE)
}
```

It looks like the function is doing what it is supposed to be doing according to the plot below.

```{r}
boot_samples(weather_df) %>% 
  ggplot(aes(x = tmin, y = tmax)) + 
  geom_point(alpha = .5) +
  stat_smooth(method = "lm") +
  labs(
    title = "Repeated Sampling",
    x = "Tmin",
    y = "Tmax")
```

**Let's now draw 5000 bootstrap samples:**

```{r}
boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_samples(sim_df_nonconst))
  )
boot_straps
```

Let's now produce estimates for each bootstrap sample, compute their `log` result, and build the dataframe for r-squared estimates, then plot their distribution:

```{r}
log_beta = 
  boot_straps %>% 
  mutate(
    model = map(strap_sample, ~lm(tmax ~ tmin, data = .x)),
    coef_results = map(model, broom::tidy),
    rsquared_results = map(model, broom::glance)) %>% 
  select(-strap_sample, -model) %>% 
  unnest() %>%
  select(strap_number, term, estimate, r.squared, adj.r.squared)

# dataframe for coefficients
log_coeff = 
  log_beta %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>% 
  janitor::clean_names() %>% 
  mutate(
    log_estimate = log(intercept * tmin))

# dataframe for r-squared
rsquared_df = 
  log_beta %>% 
  select(strap_number, r.squared, adj.r.squared) %>% 
  distinct()
```


**Density Plot for both r-squared and coefficient estimates:**

```{r}
log_plot = 
  log_coeff %>% 
  ggplot(aes(x = log_estimate)) +
  geom_density(color = "green") +
  labs(
    title = "Distribution of Log intercept and Slope",
    x = "Log Estimates",
    y = "Density")

rsquared_plot = 
  rsquared_df %>% 
  ggplot(aes(x = r.squared)) +
  geom_density(color = "red") +
  labs(
    title = "Distribution of the goodness of fit",
    x = "R-squared",
    y = "Density")

gridExtra::grid.arrange(log_plot, rsquared_plot, ncol = 2)
```

The `log(beta_0*beta_1)` looks normally distributed and so does the r-squared (goodness of fit) plot.

**95% Confidence Interval for the log coefficient:**

```{r}
quantile(pull(log_coeff, log_estimate), c(0.025, 0.975))
```
**95% Confidence Interval for R-squared:**

```{r}
quantile(pull(rsquared_df, r.squared), c(0.025, 0.975))
```
























































